{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNMF-E demo pipeline: Intro \n",
    "This complete pipeline for processing 1p microendoscopic data using CaImAn, which includes the :\n",
    "\n",
    "![workflow diagram](../../docs/img/full_cnmfe_workflow.jpg)\n",
    "\n",
    "1. Apply the NoRMCorre (nonrigid motion correction) algorithm for motion correction.\n",
    "2. Apply the constrained nonnegative matrix factorization endoscopic (CNMF-E) source separation algorithm to extract an initial estimate of neuronal spatial footprint and calcium traces.\n",
    "3. Apply quality control metrics to evaluate the initial estimates, and narrow down to the final set of estimates.\n",
    "\n",
    "Some basic visualizations are also included. \n",
    "\n",
    "> This demo follows a similar pattern to the CNMF demo in `demo_pipeline.ipynb`, but includes less explanation except where there are important differences. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and general setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from IPython import get_ipython\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import psutil\n",
    "\n",
    "import caiman as cm\n",
    "from caiman.source_extraction import cnmf\n",
    "from caiman.utils.utils import download_demo\n",
    "from caiman.utils.visualization import inspect_correlation_pnr, nb_inspect_correlation_pnr\n",
    "from caiman.motion_correction import MotionCorrect\n",
    "from caiman.source_extraction.cnmf import params as params\n",
    "from caiman.utils.visualization import plot_contours, nb_view_patches, nb_plot_contour\n",
    "from caiman.utils.visualization import view_quilt\n",
    "\n",
    "try:\n",
    "    if __IPYTHON__:\n",
    "        get_ipython().run_line_magic('load_ext', 'autoreload')\n",
    "        get_ipython().run_line_magic('autoreload', '2')\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    cv2.setNumThreads(0)\n",
    "except:\n",
    "    pass\n",
    "import bokeh.plotting as bpl\n",
    "import holoviews as hv\n",
    "\n",
    "bpl.output_notebook()\n",
    "hv.notebook_extension('bokeh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up logger and environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up logging\n",
    "logging.basicConfig(format=\"{asctime} - {levelname} - [{filename} {funcName}() {lineno}] - pid {process} - {message}\",\n",
    "                    filename=None, \n",
    "                    level=logging.WARNING, style=\"{\") #logging level can be DEBUG, INFO, WARNING, ERROR, CRITICAL\n",
    "\n",
    "# set env variables \n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select file(s) to be processed\n",
    "Here, we analyze the data in `data_endoscope.tif`. The `download_demo` function will download the  file for you and return the complete path to the file which will be stored in your `caiman_data` directory. If you adapt this demo for your data make sure to pass the complete path to your file. \n",
    "\n",
    "Note that the memory requirement of the CNMF-E algorithm are much higher compared to the standard CNMF algorithm. You should test your system before trying to process very large amounts of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_path = download_demo('data_endoscope.tif')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and visualize raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# press q to close\n",
    "movie_orig = cm.load(movie_path) \n",
    "downsampling_ratio = 0.2  # subsample 5x\n",
    "movie_orig.resize(fz=downsampling_ratio).play(gain=0.9,\n",
    "                                              q_max=99.5, \n",
    "                                              fr=30,\n",
    "                                              plot_text=True,\n",
    "                                              magnification=2,\n",
    "                                              do_loop=False,\n",
    "                                              backend='opencv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up a cluster\n",
    "To enable parallel we will set up a local cluster. The variable `backend` determines the type of cluster used. The default value `'multiprocessing'` uses the multiprocessing package. The `ipyparallel` option is also available. More information on these choices can be found [here](https://github.com/flatironinstitute/CaImAn/blob/main/docs/CLUSTER.md). The resulting variable `cluster` contains the pool of processors (CPUs) that will be used in later steps. If you use `dview=cluster` in later steps, then parallel processing will be used. If you use `dview=None` then no parallel processing will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"You have {psutil.cpu_count()} CPUs available in your current environment\")\n",
    "num_processors_to_use = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up a cluster of processors. If one has already been set up (the multiprocessing_pool variable is already in your namespace), then that cluster will be closed and a new one created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% start a cluster for parallel processing (if a cluster already exists it will be closed and a new session will be opened)\n",
    "if 'cluster' in locals():  # 'locals' contains list of current local variables\n",
    "    print('Closing previous cluster')\n",
    "    cm.stop_server(dview=cluster)\n",
    "print(\"Setting up new cluster\")\n",
    "_, cluster, n_processes = cm.cluster.setup_cluster(backend='multiprocessing', \n",
    "                                                 n_processes=num_processors_to_use, \n",
    "                                                 ignore_preexisting=False)\n",
    "print(f\"Successfully set up cluster with {n_processes} processes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup some parameters\n",
    "We first set some parameters related to the data and motion correction and create a `params` object. We'll modify this object with additional settings later on. You can also set all the parameters at once as demonstrated in the `demo_pipeline.ipynb` notebook.\n",
    "\n",
    "Note here we are setting `pw_rigid` to `False` as our data seems to contain only large-scale translational motion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dataset dependent parameters\n",
    "frate = 10                       # movie frame rate\n",
    "decay_time = 0.4                 # length of a typical transient in seconds\n",
    "\n",
    "# motion correction parameters\n",
    "motion_correct = True    # flag for performing motion correction\n",
    "pw_rigid = False         # flag for performing piecewise-rigid motion correction (otherwise just rigid)\n",
    "gSig_filt = (3, 3)       # size of high pass spatial filtering, used in 1p data\n",
    "max_shifts = (5, 5)      # maximum allowed rigid shift\n",
    "strides = (48, 48)       # start a new patch for pw-rigid motion correction every x pixels\n",
    "overlaps = (24, 24)      # overlap between pathes (size of patch strides+overlaps)\n",
    "max_deviation_rigid = 3  # maximum deviation allowed for patch with respect to rigid shifts\n",
    "border_nan = 'copy'      # replicate values along the boundaries\n",
    "\n",
    "mc_dict = {\n",
    "    'fnames': movie_path,\n",
    "    'fr': frate,\n",
    "    'decay_time': decay_time,\n",
    "    'pw_rigid': pw_rigid,\n",
    "    'max_shifts': max_shifts,\n",
    "    'gSig_filt': gSig_filt,\n",
    "    'strides': strides,\n",
    "    'overlaps': overlaps,\n",
    "    'max_deviation_rigid': max_deviation_rigid,\n",
    "    'border_nan': border_nan\n",
    "}\n",
    "\n",
    "parameters = params.CNMFParams(params_dict=mc_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motion Correction\n",
    "The background signal in micro-endoscopic data is very strong and makes the motion correction challenging. As a first step the algorithm performs a high pass spatial filtering with a Gaussian kernel to remove the bulk of the background and enhance spatial landmarks. The size of the kernel is given from the parameter `gSig_filt`. If this is left to the default value of `None` then no spatial filtering is performed (default option, used in 2p data). \n",
    "\n",
    "After spatial filtering, the NoRMCorre algorithm is used to determine the motion in each frame. The inferred motion is then applied to the *original* data so no information is lost. The motion corrected files are saved in memory mapped format. If no motion correction is  performed, then the file gets directly memory mapped.\n",
    "\n",
    "The following also plots the discovered displacements in x- and y- in the movie (for a detailed exploration of Caiman's motion correction pipeline, see `demo_motion_correction.ipynb`).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if motion_correct:\n",
    "    # do motion correction rigid\n",
    "    mot_correct = MotionCorrect(movie_path, dview=cluster, **parameters.get_group('motion'))\n",
    "    mot_correct.motion_correct(save_movie=True)\n",
    "    fname_mc = mot_correct.fname_tot_els if pw_rigid else mot_correct.fname_tot_rig\n",
    "    if pw_rigid:\n",
    "        bord_px = np.ceil(np.maximum(np.max(np.abs(mot_correct.x_shifts_els)),\n",
    "                                     np.max(np.abs(mot_correct.y_shifts_els)))).astype(int)\n",
    "    else:\n",
    "        bord_px = np.ceil(np.max(np.abs(mot_correct.shifts_rig))).astype(int)\n",
    "        # Plot shifts\n",
    "        plt.plot(mot_correct.shifts_rig)  # % plot rigid shifts\n",
    "        plt.legend(['x shifts', 'y shifts'])\n",
    "        plt.xlabel('frames')\n",
    "        plt.ylabel('pixels')\n",
    "        plt.gcf().set_size_inches(6,3)\n",
    "\n",
    "    bord_px = 0 if border_nan == 'copy' else bord_px\n",
    "    fname_new = cm.save_memmap(fname_mc, base_name='memmap_', order='C',\n",
    "                               border_to_0=bord_px)\n",
    "else:  # if no motion correction just memory map the file\n",
    "    fname_new = cm.save_memmap(movie_path, base_name='memmap_',\n",
    "                               order='C', border_to_0=0, dview=dview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare original and motion corrected movie. Note they look pretty similar, as there wasn't much motion to begin with. You can see in the shift plot that the shifts were all below one pixel!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_corrected = cm.load(mot_correct.mmap_file) # load motion corrected movie\n",
    "ds_ratio = 0.2\n",
    "cm.concatenate([movie_orig.resize(1, 1, ds_ratio) - mot_correct.min_mov*mot_correct.nonneg_movie,\n",
    "                movie_corrected.resize(1, 1, ds_ratio)], \n",
    "                axis=2).play(fr=20, \n",
    "                             gain=0.9, \n",
    "                             magnification=2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load memory mapped file\n",
    "Memory mapping is discussed in some detail in `demo_pipeline.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load memory mappable file\n",
    "Yr, dims, T = cm.load_memmap(fname_new)\n",
    "images = Yr.T.reshape((T,) + dims, order='F')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter setting for CNMF-E\n",
    "We now define some parameters for the source extraction step using the CNMF-E algorithm. \n",
    "We construct a new dictionary and use this to modify the *existing* `params` object, using the `change_params()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for source extraction and deconvolution\n",
    "p = 1               # order of the autoregressive system\n",
    "K = None            # upper bound on number of components per patch, in general None for CNMFE\n",
    "gSig = np.array([3, 3])  # expected half-width of neurons in pixels \n",
    "gSiz = 4*gSig + 1     # half-width of bounding box created around neurons during initialization\n",
    "merge_thr = .7      # merging threshold, max correlation allowed\n",
    "rf = 40             # half-size of the patches in pixels. e.g., if rf=40, patches are 80x80\n",
    "stride_cnmf = 20    # amount of overlap between the patches in pixels \n",
    "tsub = 2            # downsampling factor in time for initialization, increase if you have memory problems\n",
    "ssub = 1            # downsampling factor in space for initialization, increase if you have memory problems\n",
    "low_rank_background = None  # None leaves background of each patch intact,\n",
    "#                     True performs global low-rank approximation if gnb>0\n",
    "gnb = 0             # number of background components (rank) if positive, set to 0 for CNMFE ring model\n",
    "nb_patch = 0        # number of background components (rank) per patch (0 for CNMFE)\n",
    "min_corr = .8       # min peak value from correlation image\n",
    "min_pnr = 10        # min peak to noise ration from PNR image\n",
    "ssub_B = 1          # additional downsampling factor in space for background (increase to 2 if slow)\n",
    "ring_size_factor = 1.4  # radius of ring is gSiz*ring_size_factor\n",
    "\n",
    "parameters.change_params(params_dict={'method_init': 'corr_pnr',  # use this for 1 photon\n",
    "                                'K': K,\n",
    "                                'gSig': gSig,\n",
    "                                'gSiz': gSiz,\n",
    "                                'merge_thr': merge_thr,\n",
    "                                'p': p,\n",
    "                                'tsub': tsub,\n",
    "                                'ssub': ssub,\n",
    "                                'rf': rf,\n",
    "                                'stride': stride_cnmf,\n",
    "                                'only_init': True,    # set it to True to run CNMF-E\n",
    "                                'nb': gnb,\n",
    "                                'nb_patch': nb_patch,\n",
    "                                'method_deconvolution': 'oasis',       # could use 'cvxpy' alternatively\n",
    "                                'low_rank_background': low_rank_background,\n",
    "                                'update_background_components': True,  # sometimes setting to False improve the results\n",
    "                                'min_corr': min_corr,\n",
    "                                'min_pnr': min_pnr,\n",
    "                                'normalize_init': False,               # just leave as is\n",
    "                                'center_psf': True,                    # leave as is for 1 photon\n",
    "                                'ssub_B': ssub_B,\n",
    "                                'ring_size_factor': ring_size_factor,\n",
    "                                'del_duplicates': True,                # whether to remove duplicates from initialization\n",
    "                                'border_pix': bord_px})                # number of pixels to not consider in the borders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnmfe_model = cnmf.CNMF(n_processes=n_processes, \n",
    "                        dview=cluster, \n",
    "                        params=parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quilt plot for spatial parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate stride and overlap from parameters\n",
    "cnmfe_patch_width = cnmfe_model.params.patch['rf']*2 + 1\n",
    "cnmfe_patch_overlap = cnmfe_model.params.patch['stride'] + 1\n",
    "cnmfe_patch_stride = cnmfe_patch_width - cnmfe_patch_overlap\n",
    "print(f'Patch width: {cnmfe_patch_width} , Stride: {cnmfe_patch_stride}, Overlap: {cnmfe_patch_overlap}');\n",
    "\n",
    "# plot the patches\n",
    "patch_ax = view_quilt(correlation_image, \n",
    "                      cnmfe_patch_stride, \n",
    "                      cnmfe_patch_overlap, \n",
    "                      vmin=np.percentile(np.ravel(correlation_image),50), \n",
    "                      vmax=np.percentile(np.ravel(correlation_image),99.5),\n",
    "                      figsize=(4,4));\n",
    "patch_ax.set_title(f'CNMFE Patches Width {cnmfe_patch_width}, Overlap {cnmfe_patch_overlap}');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect corr-pnr image to determine min_corr and min_pnr\n",
    "Check the optimal values of `min_corr` and `min_pnr` by moving slider in the figure that pops up. You can modify them in the `params` object. Note that computing the correlation and peak-noise-ratio images can be computationally and memory demanding for large datasets. In this case you can compute only on a subset of the data (the results will not change). You can do that by changing `images[::1]` to `images[::5]` or something similar.\n",
    "\n",
    "This will compute the correlation pnr image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm.summary_images.correlation_pnr?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute some summary images (correlation and peak to noise)\n",
    "correlation_image, peak_to_noise_ratio = cm.summary_images.correlation_pnr(images[::1], \n",
    "                                                                           gSig=gSig[0], \n",
    "                                                                           swap_dim=False) # change swap dim if output looks weird, it is a problem with tiffile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_inspect_correlation_pnr?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the summary images and set the parameters\n",
    "# mention option of  inspect_correlation_pnr\n",
    "nb_inspect_correlation_pnr(correlation_image, peak_to_noise_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can inspect the correlation and PNR images to select the threshold values for `min_corr` and `min_pnr`. The algorithm will look for components only in places where these value are above the specified thresholds. You can adjust the dynamic range in the plots shown above by choosing the selection tool (third button from the left) and selecting the desired region in the histogram plots on the right of each panel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print parameters set above, modify them if necessary based on summary images\n",
    "print(min_corr) # min correlation of peak (from correlation image)\n",
    "print(min_pnr)  # min peak to noise ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adjust corr / pnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# min_corr  = 0.6  # 0.7 0.4 # 0.66 #0.74\n",
    "# min_pnr = 6      #3  #2 #4.3 # 8.5 \n",
    "# opts.change_params(params_dict={'min_corr': min_corr, \n",
    "#                                 'min_pnr': min_pnr});\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the CNMF-E algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cnmfe_model.fit(images);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnmfe_model.estimates.b0.shape, cnmfe_model.estimates.W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnmfe_background = cnmfe_model.estimates.compute_background(Yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnmfe_background.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternate way to run the pipeline at once  (make this blue)\n",
    "It is possible to run the combined steps of motion correction, memory mapping, and cnmf fitting in one step as shown below. The command is commented out since the analysis has already been performed. It is recommended that you familiriaze yourself with the various steps and the results of the various steps before using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnmfe_all = cnmf.CNMF(n_processes, params=parameters, dview=cluster)\n",
    "# cnmfe_all.fit_file(motion_correct=motion_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component Evaluation\n",
    "\n",
    "The processing in patches creates several spurious components. These are filtered out by evaluating each component using three different criteria:\n",
    "\n",
    "- the shape of each component must be correlated with the data at the corresponding location within the FOV\n",
    "- a minimum peak SNR is required over the length of a transient\n",
    "- each shape passes a CNN based classifier\n",
    "\n",
    "<img src=\"../../docs/img/evaluationcomponent.png\"/>\n",
    "After setting some parameters we again modify the existing `params` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% COMPONENT EVALUATION\n",
    "# the components are evaluated in two ways:\n",
    "#   a) the shape of each component must be correlated with the data\n",
    "#   b) a minimum peak SNR is required over the length of a transient\n",
    "# Note that here we do not use the CNN based classifier, because it was trained on 2p not 1p data\n",
    "\n",
    "min_SNR = 3            # adaptive way to set threshold on the transient size\n",
    "r_values_min = 0.85    # threshold on space consistency (if you lower more components\n",
    "#                        will be accepted, potentially with worst quality)\n",
    "cnmfe_model.params.set('quality', {'min_SNR': min_SNR,\n",
    "                           'rval_thr': r_values_min,\n",
    "                           'use_cnn': False})\n",
    "cnmfe_model.estimates.evaluate_components(images, cnmfe_model.params, dview=cluster)\n",
    "\n",
    "print(' ***** ')\n",
    "print('Number of total components: ', len(cnmfe_model.estimates.C))\n",
    "print('Number of accepted components: ', len(cnmfe_model.estimates.idx_components))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do some plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%% plot contour plots of accepted and rejected components\n",
    "cnmfe_model.estimates.plot_contours_nb(img=correlation_image, \n",
    "                               idx=cnmfe_model.estimates.idx_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View traces of accepted and rejected components. Note that if you get data rate error you can start Jupyter notebooks using:\n",
    "'jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accepted components\n",
    "cnmfe_model.estimates.hv_view_components(img=correlation_image, \n",
    "                                 idx=cnmfe_model.estimates.idx_components,\n",
    "                                 denoised_color='red', \n",
    "                                 cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rejected components\n",
    "cnmfe_model.estimates.hv_view_components(img=correlation_image, \n",
    "                                         idx=cnmfe_model.estimates.idx_components_bad,\n",
    "                                         denoised_color='red', \n",
    "                                         cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save/load data (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some instructive movies\n",
    "Something something Wb as background model. \n",
    "\n",
    "\n",
    "Play the reconstructed movie alongside the original movie and the (amplified) residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with background \n",
    "cnmfe_model.estimates.play_movie(images, \n",
    "                                 q_max=99.5, \n",
    "                                 magnification=2,\n",
    "                                 include_bck=True, \n",
    "                                 gain_res=10, \n",
    "                                 bpx=bord_px);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without background\n",
    "cnmfe_model.estimates.play_movie(images, \n",
    "                         q_max=99.9, \n",
    "                         magnification=2,\n",
    "                         include_bck=False,\n",
    "                         gain_res=4,\n",
    "                         bpx=bord_px);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up resourses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm.stop_server(dview=dview)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
